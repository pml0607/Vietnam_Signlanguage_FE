{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1RN9RveGRqf"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_global_stats(csv_file, max_frames=180):\n",
        "    data = pd.read_csv(csv_file)\n",
        "    x = []\n",
        "    y = []\n",
        "    for npy_path in tqdm(data['file_path'], desc=\"Computing global stats (CPU)\"):\n",
        "        data_np = np.load(npy_path)\n",
        "        if data_np.shape[0] > max_frames:\n",
        "            data_np = data_np[:max_frames]\n",
        "        x.append(data_np[:, :, 0].flatten())\n",
        "        y.append(data_np[:, :, 1].flatten())\n",
        "    x = np.concatenate(x, axis=0)\n",
        "    y = np.concatenate(y, axis=0)\n",
        "    w = x.max() - x.min() + 1e-6\n",
        "    h = y.max() - y.min() + 1e-6\n",
        "    x_min = x.min()\n",
        "    y_min = y.min()\n",
        "    return {'w': w, 'h': h, 'x_min': x_min, 'y_min': y_min}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bxjUfoQ3GfXJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_corpus_csv(csv_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    video_paths = df['video_path'].tolist()\n",
        "    landmark_paths = df['file_path'].tolist()\n",
        "    labels = df['label'].tolist()\n",
        "    return video_paths, landmark_paths, labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing global stats (CPU): 100%|██████████| 2135/2135 [00:02<00:00, 1061.48it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "stats = compute_global_stats('cnn_train.corpus.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_landmark(data_np, stats):\n",
        "    # data_np: [T, N, 2]\n",
        "    data_np = data_np.copy()  \n",
        "\n",
        "    data_np[:, :, 0] = (data_np[:, :, 0] - stats['x_min']) / stats['w']\n",
        "    data_np[:, :, 1] = (data_np[:, :, 1] - stats['y_min']) / stats['h']\n",
        "    return data_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFycqMoOGg0f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def process_sample(video_path, landmark_path, label,\n",
        "                   num_frames=64, stride=64, feature_dim=None):\n",
        "    import os\n",
        "\n",
        "    video_path = video_path.numpy().decode(\"utf-8\")\n",
        "    landmark_path = landmark_path.numpy().decode(\"utf-8\")\n",
        "\n",
        "    # ========== Load video ==========\n",
        "    try:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        frames = []\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = cv2.resize(frame, (224, 224))\n",
        "            frame = (frame / 127.5) - 1.0\n",
        "            frames.append(frame)\n",
        "        cap.release()\n",
        "\n",
        "        if len(frames) == 0 or not os.path.exists(landmark_path):\n",
        "            return (\n",
        "                np.empty((0, num_frames, 224, 224, 3), dtype=np.float32),\n",
        "                np.empty((0, num_frames, 225), dtype=np.float32),\n",
        "                np.empty((0,), dtype=np.int32)\n",
        "            )\n",
        "    except e:\n",
        "        print(\"error\" + e)\n",
        "\n",
        "    # ========== Load landmark ==========\n",
        "    landmark = np.load(landmark_path)\\\n",
        "\n",
        "    \n",
        "    if len(landmark.shape) == 3 and landmark.shape[2] == 3:\n",
        "        landmark = landmark.reshape((landmark.shape[0], -1))  # [T, 225]\n",
        "    elif len(landmark.shape) != 2:\n",
        "        print(f\"[ERROR] Unsupported landmark shape: {landmark.shape}\")\n",
        "        return (\n",
        "            np.empty((0, num_frames, 224, 224, 3), dtype=np.float32),\n",
        "            np.empty((0, num_frames, 225), dtype=np.float32),\n",
        "            np.empty((0,), dtype=np.int32)\n",
        "        )\n",
        "    \n",
        "    feature_dim = landmark.shape[1]\n",
        "\n",
        "    # ========== Chunk ==========\n",
        "    rgb_chunks, lm_chunks, label_chunks = [], [], []\n",
        "\n",
        "    for start in range(0, len(frames), stride):\n",
        "        rgb_clip = frames[start:start + num_frames]\n",
        "        lm_clip = landmark[start:start + num_frames]\n",
        "\n",
        "        if len(rgb_clip) < num_frames:\n",
        "            rgb_clip += [np.zeros((224, 224, 3))] * (num_frames - len(rgb_clip))\n",
        "        if len(lm_clip) < num_frames:\n",
        "            pad = np.zeros((num_frames - len(lm_clip), feature_dim))\n",
        "            lm_clip = np.concatenate([lm_clip, pad], axis=0)\n",
        "\n",
        "        rgb_clip = np.array(rgb_clip, dtype=np.float32)\n",
        "        lm_clip = np.array(lm_clip, dtype=np.float32)\n",
        "\n",
        "        # ✅ Debug\n",
        "        print(f\"[DEBUG] rgb_clip shape: {rgb_clip.shape}\")\n",
        "        print(f\"[DEBUG] lm_clip shape: {lm_clip.shape}\")\n",
        "\n",
        "        rgb_chunks.append(rgb_clip)\n",
        "        lm_chunks.append(lm_clip)\n",
        "        label_chunks.append(np.int32(label))\n",
        "\n",
        "    # Nếu không có đoạn nào được tạo (do vòng for không chạy)\n",
        "    if len(rgb_chunks) == 0:\n",
        "        return (\n",
        "            np.empty((0, num_frames, 224, 224, 3), dtype=np.float32),\n",
        "            np.empty((0, num_frames, feature_dim), dtype=np.float32),\n",
        "            np.empty((0,), dtype=np.int32)\n",
        "        )\n",
        "\n",
        "    return (\n",
        "        np.stack(rgb_chunks, axis=0),\n",
        "        np.stack(lm_chunks, axis=0),\n",
        "        np.array(label_chunks, dtype=np.int32)\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yWHBX-5RG1vi"
      },
      "outputs": [],
      "source": [
        "def tf_process_sample(video_path, landmark_path, label):\n",
        "    rgb_lm_label = tf.py_function(\n",
        "        func=process_sample,\n",
        "        inp=[video_path, landmark_path, label],\n",
        "        Tout=[tf.float32, tf.float32, tf.int32]\n",
        "    )\n",
        "    return rgb_lm_label\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-_QGY3xLIamK"
      },
      "outputs": [],
      "source": [
        "def create_dataset_from_csv(csv_path, batch_size=8, shuffle=True):\n",
        "    video_paths, landmark_paths, labels = load_corpus_csv(csv_path)\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((video_paths, landmark_paths, labels))\n",
        "\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=len(video_paths))\n",
        "\n",
        "    dataset = dataset.map(\n",
        "        lambda v, l, y: tf.py_function(\n",
        "            func=process_sample,\n",
        "            inp=[v, l, y],\n",
        "            Tout=[tf.float32, tf.float32, tf.int32]\n",
        "        ),\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "\n",
        "    dataset = dataset.flat_map(\n",
        "        lambda rgb, lm, label: tf.data.Dataset.from_tensor_slices((rgb, lm, label))\n",
        "    )\n",
        "\n",
        "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "49OcVzceHFkb"
      },
      "outputs": [
        {
          "ename": "InvalidArgumentError",
          "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Error in user-defined function passed to ParallelMapDatasetV2:16 transformation with iterator: Iterator::Root::Prefetch::FiniteTake::Prefetch::BatchV2::FlatMap::ParallelMapV2: TypeError: can only concatenate str (not \"int\") to str\nTraceback (most recent call last):\n\n  File \"c:\\Users\\phamm\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 267, in __call__\n    return func(device, token, args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\phamm\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 145, in __call__\n    outputs = self._call(device, args)\n              ^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\phamm\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 152, in _call\n    ret = self._func(*args)\n          ^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\phamm\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\phamm\\AppData\\Local\\Temp\\ipykernel_7076\\3896014797.py\", line 50, in process_sample\n    print(\"Feature dim:\" +  feature_dim)\n          ~~~~~~~~~~~~~~~^~~~~~~~~~~~~~\n\nTypeError: can only concatenate str (not \"int\") to str\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext] name: ",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m create_dataset_from_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn_val.corpus.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Ví dụ test:\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rgb, lm, label \u001b[38;5;129;01min\u001b[39;00m train_dataset\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(rgb\u001b[38;5;241m.\u001b[39mshape)      \u001b[38;5;66;03m# [B, 64, 224, 224, 3]\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(lm\u001b[38;5;241m.\u001b[39mshape)       \u001b[38;5;66;03m# [B, 64, 225]\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\phamm\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:826\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    825\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_internal()\n\u001b[0;32m    827\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\phamm\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:776\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 776\u001b[0m   ret \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39miterator_get_next(\n\u001b[0;32m    777\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource,\n\u001b[0;32m    778\u001b[0m       output_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types,\n\u001b[0;32m    779\u001b[0m       output_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_shapes)\n\u001b[0;32m    781\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\phamm\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3086\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3084\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3085\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 3086\u001b[0m   _ops\u001b[38;5;241m.\u001b[39mraise_from_not_ok_status(e, name)\n\u001b[0;32m   3087\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m   3088\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\phamm\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6006\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6004\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   6005\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 6006\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Error in user-defined function passed to ParallelMapDatasetV2:16 transformation with iterator: Iterator::Root::Prefetch::FiniteTake::Prefetch::BatchV2::FlatMap::ParallelMapV2: TypeError: can only concatenate str (not \"int\") to str\nTraceback (most recent call last):\n\n  File \"c:\\Users\\phamm\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 267, in __call__\n    return func(device, token, args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\phamm\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 145, in __call__\n    outputs = self._call(device, args)\n              ^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\phamm\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 152, in _call\n    ret = self._func(*args)\n          ^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\phamm\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\phamm\\AppData\\Local\\Temp\\ipykernel_7076\\3896014797.py\", line 50, in process_sample\n    print(\"Feature dim:\" +  feature_dim)\n          ~~~~~~~~~~~~~~~^~~~~~~~~~~~~~\n\nTypeError: can only concatenate str (not \"int\") to str\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext] name: "
          ]
        }
      ],
      "source": [
        "train_dataset = create_dataset_from_csv(\"cnn_train.corpus.csv\", batch_size=8)\n",
        "val_dataset = create_dataset_from_csv(\"cnn_val.corpus.csv\", batch_size=8)\n",
        "\n",
        "# Ví dụ test:\n",
        "for rgb, lm, label in train_dataset.take(1):\n",
        "    print(rgb.shape)      # [B, 64, 224, 224, 3]\n",
        "    print(lm.shape)       # [B, 64, 225]\n",
        "    print(label.shape)    # [B]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7tfFXqxGcN8"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3rYKQJCv4Ti",
        "outputId": "3c7ccc20-bd39-4fe2-cbeb-32df2ba58c2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping sonnet as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting dm-sonnet\n",
            "  Downloading dm_sonnet-2.0.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from dm-sonnet) (1.4.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from dm-sonnet) (0.1.9)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.11/dist-packages (from dm-sonnet) (2.0.2)\n",
            "Requirement already satisfied: tabulate>=0.7.5 in /usr/local/lib/python3.11/dist-packages (from dm-sonnet) (0.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from dm-sonnet) (1.17.2)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree>=0.1.1->dm-sonnet) (25.3.0)\n",
            "Downloading dm_sonnet-2.0.2-py3-none-any.whl (268 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.4/268.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dm-sonnet\n",
            "Successfully installed dm-sonnet-2.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall sonnet -y\n",
        "!pip install dm-sonnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KvsQsgZ9vsGb"
      },
      "outputs": [],
      "source": [
        "# Copyright 2017 Google Inc.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ============================================================================\n",
        "\"\"\"Inception-v1 Inflated 3D ConvNet used for Kinetics CVPR paper.\n",
        "\n",
        "The model is introduced in:\n",
        "\n",
        "  Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\n",
        "  Joao Carreira, Andrew Zisserman\n",
        "  https://arxiv.org/pdf/1705.07750v1.pdf.\n",
        "\"\"\"\n",
        "import sonnet as snt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, layers\n",
        "\n",
        "\n",
        "class Unit3D(snt.Module):\n",
        "  \"\"\"Basic unit containing Conv3D + BatchNorm + non-linearity.\"\"\"\n",
        "\n",
        "  def __init__(self, output_channels,\n",
        "               kernel_shape=(1, 1, 1),\n",
        "               stride=(1, 1, 1),\n",
        "               activation_fn=tf.nn.relu,\n",
        "               use_batch_norm=True,\n",
        "               use_bias=False,\n",
        "               name='unit_3d'):\n",
        "    \"\"\"Initializes Unit3D module.\"\"\"\n",
        "    super(Unit3D, self).__init__(name=name)\n",
        "    self._output_channels = output_channels\n",
        "    self._kernel_shape = kernel_shape\n",
        "    self._stride = stride\n",
        "    self._use_batch_norm = use_batch_norm\n",
        "    self._activation_fn = activation_fn\n",
        "    self._use_bias = use_bias\n",
        "\n",
        "  def _build(self, inputs, is_training):\n",
        "    \"\"\"Connects the module to inputs.\n",
        "\n",
        "    Args:\n",
        "      inputs: Inputs to the Unit3D component.\n",
        "      is_training: whether to use training mode for snt.BatchNorm (boolean).\n",
        "\n",
        "    Returns:\n",
        "      Outputs from the module.\n",
        "    \"\"\"\n",
        "    net = snt.Conv3D(output_channels=self._output_channels,\n",
        "                     kernel_shape=self._kernel_shape,\n",
        "                     stride=self._stride,\n",
        "                     padding=snt.SAME,\n",
        "                     use_bias=self._use_bias)(inputs)\n",
        "    if self._use_batch_norm:\n",
        "      bn = snt.BatchNorm()\n",
        "      net = bn(net, is_training=is_training, test_local_stats=False)\n",
        "    if self._activation_fn is not None:\n",
        "      net = self._activation_fn(net)\n",
        "    return net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iB6IpwEY6qO6"
      },
      "outputs": [],
      "source": [
        "class InceptionI3d(snt.Module):\n",
        "  \"\"\"Inception-v1 I3D architecture.\n",
        "\n",
        "  The model is introduced in:\n",
        "\n",
        "    Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\n",
        "    Joao Carreira, Andrew Zisserman\n",
        "    https://arxiv.org/pdf/1705.07750v1.pdf.\n",
        "\n",
        "  See also the Inception architecture, introduced in:\n",
        "\n",
        "    Going deeper with convolutions\n",
        "    Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed,\n",
        "    Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich.\n",
        "    http://arxiv.org/pdf/1409.4842v1.pdf.\n",
        "  \"\"\"\n",
        "\n",
        "  # Endpoints of the model in order. During construction, all the endpoints up\n",
        "  # to a designated `final_endpoint` are returned in a dictionary as the\n",
        "  # second return value.\n",
        "  VALID_ENDPOINTS = (\n",
        "      'Conv3d_1a_7x7',\n",
        "      'MaxPool3d_2a_3x3',\n",
        "      'Conv3d_2b_1x1',\n",
        "      'Conv3d_2c_3x3',\n",
        "      'MaxPool3d_3a_3x3',\n",
        "      'Mixed_3b',\n",
        "      'Mixed_3c',\n",
        "      'MaxPool3d_4a_3x3',\n",
        "      'Mixed_4b',\n",
        "      'Mixed_4c',\n",
        "      'Mixed_4d',\n",
        "      'Mixed_4e',\n",
        "      'Mixed_4f',\n",
        "      'MaxPool3d_5a_2x2',\n",
        "      'Mixed_5b',\n",
        "      'Mixed_5c',\n",
        "      'Logits',\n",
        "      'Predictions',\n",
        "  )\n",
        "\n",
        "  def __init__(self, num_classes=15, spatial_squeeze=True,\n",
        "               final_endpoint='Logits', name='inception_i3d'):\n",
        "    \"\"\"Initializes I3D model instance.\n",
        "\n",
        "    Args:\n",
        "      num_classes: The number of outputs in the logit layer (default 400, which\n",
        "          matches the Kinetics dataset).\n",
        "      spatial_squeeze: Whether to squeeze the spatial dimensions for the logits\n",
        "          before returning (default True).\n",
        "      final_endpoint: The model contains many possible endpoints.\n",
        "          `final_endpoint` specifies the last endpoint for the model to be built\n",
        "          up to. In addition to the output at `final_endpoint`, all the outputs\n",
        "          at endpoints up to `final_endpoint` will also be returned, in a\n",
        "          dictionary. `final_endpoint` must be one of\n",
        "          InceptionI3d.VALID_ENDPOINTS (default 'Logits').\n",
        "      name: A string (optional). The name of this module.\n",
        "\n",
        "    Raises:\n",
        "      ValueError: if `final_endpoint` is not recognized.\n",
        "    \"\"\"\n",
        "\n",
        "    if final_endpoint not in self.VALID_ENDPOINTS:\n",
        "      raise ValueError('Unknown final endpoint %s' % final_endpoint)\n",
        "\n",
        "    super(InceptionI3d, self).__init__(name=name)\n",
        "    self._num_classes = num_classes\n",
        "    self._spatial_squeeze = spatial_squeeze\n",
        "    self._final_endpoint = final_endpoint\n",
        "\n",
        "  def _build(self, inputs, is_training, dropout_keep_prob=1.0):\n",
        "    \"\"\"Connects the model to inputs.\n",
        "\n",
        "    Args:\n",
        "      inputs: Inputs to the model, which should have dimensions\n",
        "          `batch_size` x `num_frames` x 224 x 224 x `num_channels`.\n",
        "      is_training: whether to use training mode for snt.BatchNorm (boolean).\n",
        "      dropout_keep_prob: Probability for the tf.nn.dropout layer (float in\n",
        "          [0, 1)).\n",
        "\n",
        "    Returns:\n",
        "      A tuple consisting of:\n",
        "        1. Network output at location `self._final_endpoint`.\n",
        "        2. Dictionary containing all endpoints up to `self._final_endpoint`,\n",
        "           indexed by endpoint name.\n",
        "\n",
        "    Raises:\n",
        "      ValueError: if `self._final_endpoint` is not recognized.\n",
        "    \"\"\"\n",
        "    if self._final_endpoint not in self.VALID_ENDPOINTS:\n",
        "      raise ValueError('Unknown final endpoint %s' % self._final_endpoint)\n",
        "\n",
        "    net = inputs\n",
        "    end_points = {}\n",
        "    end_point = 'Conv3d_1a_7x7'\n",
        "    net = Unit3D(output_channels=64, kernel_shape=[7, 7, 7],\n",
        "                 stride=[2, 2, 2], name=end_point)(net, is_training=is_training)\n",
        "    end_points[end_point] = net\n",
        "    if self._final_endpoint == end_point: return net, end_points\n",
        "    end_point = 'MaxPool3d_2a_3x3'\n",
        "    net = tf.nn.max_pool3d(net, ksize=[1, 1, 3, 3, 1], strides=[1, 1, 2, 2, 1],\n",
        "                           padding=snt.SAME, name=end_point)\n",
        "    end_points[end_point] = net\n",
        "    if self._final_endpoint == end_point: return net, end_points\n",
        "    end_point = 'Conv3d_2b_1x1'\n",
        "    net = Unit3D(output_channels=64, kernel_shape=[1, 1, 1],\n",
        "                 name=end_point)(net, is_training=is_training)\n",
        "    end_points[end_point] = net\n",
        "    if self._final_endpoint == end_point: return net, end_points\n",
        "    end_point = 'Conv3d_2c_3x3'\n",
        "    net = Unit3D(output_channels=192, kernel_shape=[3, 3, 3],\n",
        "                 name=end_point)(net, is_training=is_training)\n",
        "    end_points[end_point] = net\n",
        "    if self._final_endpoint == end_point: return net, end_points\n",
        "    end_point = 'MaxPool3d_3a_3x3'\n",
        "    net = tf.nn.max_pool3d(net, ksize=[1, 1, 3, 3, 1], strides=[1, 1, 2, 2, 1],\n",
        "                           padding=snt.SAME, name=end_point)\n",
        "    end_points[end_point] = net\n",
        "    if self._final_endpoint == end_point: return net, end_points\n",
        "\n",
        "    end_point = 'Mixed_3b'\n",
        "    with tf.variable_scope(end_point):\n",
        "      with tf.variable_scope('Branch_0'):\n",
        "        branch_0 = Unit3D(output_channels=64, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "      with tf.variable_scope('Branch_1'):\n",
        "        branch_1 = Unit3D(output_channels=96, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "        branch_1 = Unit3D(output_channels=128, kernel_shape=[3, 3, 3],\n",
        "                          name='Conv3d_0b_3x3')(branch_1,\n",
        "                                                is_training=is_training)\n",
        "      with tf.variable_scope('Branch_2'):\n",
        "        branch_2 = Unit3D(output_channels=16, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "        branch_2 = Unit3D(output_channels=32, kernel_shape=[3, 3, 3],\n",
        "                          name='Conv3d_0b_3x3')(branch_2,\n",
        "                                                is_training=is_training)\n",
        "      with tf.variable_scope('Branch_3'):\n",
        "        branch_3 = tf.nn.max_pool3d(net, ksize=[1, 3, 3, 3, 1],\n",
        "                                    strides=[1, 1, 1, 1, 1], padding=snt.SAME,\n",
        "                                    name='MaxPool3d_0a_3x3')\n",
        "        branch_3 = Unit3D(output_channels=32, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0b_1x1')(branch_3,\n",
        "                                                is_training=is_training)\n",
        "\n",
        "      net = tf.concat([branch_0, branch_1, branch_2, branch_3], 4)\n",
        "    end_points[end_point] = net\n",
        "    if self._final_endpoint == end_point: return net, end_points\n",
        "\n",
        "    end_point = 'Mixed_3c'\n",
        "    with tf.variable_scope(end_point):\n",
        "      with tf.variable_scope('Branch_0'):\n",
        "        branch_0 = Unit3D(output_channels=128, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "      with tf.variable_scope('Branch_1'):\n",
        "        branch_1 = Unit3D(output_channels=128, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "        branch_1 = Unit3D(output_channels=192, kernel_shape=[3, 3, 3],\n",
        "                          name='Conv3d_0b_3x3')(branch_1,\n",
        "                                                is_training=is_training)\n",
        "      with tf.variable_scope('Branch_2'):\n",
        "        branch_2 = Unit3D(output_channels=32, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "        branch_2 = Unit3D(output_channels=96, kernel_shape=[3, 3, 3],\n",
        "                          name='Conv3d_0b_3x3')(branch_2,\n",
        "                                                is_training=is_training)\n",
        "      with tf.variable_scope('Branch_3'):\n",
        "        branch_3 = tf.nn.max_pool3d(net, ksize=[1, 3, 3, 3, 1],\n",
        "                                    strides=[1, 1, 1, 1, 1], padding=snt.SAME,\n",
        "                                    name='MaxPool3d_0a_3x3')\n",
        "        branch_3 = Unit3D(output_channels=64, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0b_1x1')(branch_3,\n",
        "                                                is_training=is_training)\n",
        "      net = tf.concat([branch_0, branch_1, branch_2, branch_3], 4)\n",
        "    end_points[end_point] = net\n",
        "    if self._final_endpoint == end_point: return net, end_points\n",
        "\n",
        "    end_point = 'MaxPool3d_4a_3x3'\n",
        "    net = tf.nn.max_pool3d(net, ksize=[1, 3, 3, 3, 1], strides=[1, 2, 2, 2, 1],\n",
        "                           padding=snt.SAME, name=end_point)\n",
        "    end_points[end_point] = net\n",
        "    if self._final_endpoint == end_point: return net, end_points\n",
        "\n",
        "    end_point = 'Mixed_4b'\n",
        "    with tf.variable_scope(end_point):\n",
        "      with tf.variable_scope('Branch_0'):\n",
        "        branch_0 = Unit3D(output_channels=192, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "      with tf.variable_scope('Branch_1'):\n",
        "        branch_1 = Unit3D(output_channels=96, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "        branch_1 = Unit3D(output_channels=208, kernel_shape=[3, 3, 3],\n",
        "                          name='Conv3d_0b_3x3')(branch_1,\n",
        "                                                is_training=is_training)\n",
        "      with tf.variable_scope('Branch_2'):\n",
        "        branch_2 = Unit3D(output_channels=16, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "        branch_2 = Unit3D(output_channels=48, kernel_shape=[3, 3, 3],\n",
        "                          name='Conv3d_0b_3x3')(branch_2,\n",
        "                                                is_training=is_training)\n",
        "      with tf.variable_scope('Branch_3'):\n",
        "        branch_3 = tf.nn.max_pool3d(net, ksize=[1, 3, 3, 3, 1],\n",
        "                                    strides=[1, 1, 1, 1, 1], padding=snt.SAME,\n",
        "                                    name='MaxPool3d_0a_3x3')\n",
        "        branch_3 = Unit3D(output_channels=64, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0b_1x1')(branch_3,\n",
        "                                                is_training=is_training)\n",
        "      net = tf.concat([branch_0, branch_1, branch_2, branch_3], 4)\n",
        "    end_points[end_point] = net\n",
        "    if self._final_endpoint == end_point: return net, end_points\n",
        "\n",
        "    end_point = 'Mixed_4c'\n",
        "    with tf.variable_scope(end_point):\n",
        "      with tf.variable_scope('Branch_0'):\n",
        "        branch_0 = Unit3D(output_channels=160, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "      with tf.variable_scope('Branch_1'):\n",
        "        branch_1 = Unit3D(output_channels=112, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "        branch_1 = Unit3D(output_channels=224, kernel_shape=[3, 3, 3],\n",
        "                          name='Conv3d_0b_3x3')(branch_1,\n",
        "                                                is_training=is_training)\n",
        "      with tf.variable_scope('Branch_2'):\n",
        "        branch_2 = Unit3D(output_channels=24, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "        branch_2 = Unit3D(output_channels=64, kernel_shape=[3, 3, 3],\n",
        "                          name='Conv3d_0b_3x3')(branch_2,\n",
        "                                                is_training=is_training)\n",
        "      with tf.variable_scope('Branch_3'):\n",
        "        branch_3 = tf.nn.max_pool3d(net, ksize=[1, 3, 3, 3, 1],\n",
        "                                    strides=[1, 1, 1, 1, 1], padding=snt.SAME,\n",
        "                                    name='MaxPool3d_0a_3x3')\n",
        "        branch_3 = Unit3D(output_channels=64, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0b_1x1')(branch_3,\n",
        "                                                is_training=is_training)\n",
        "      net = tf.concat([branch_0, branch_1, branch_2, branch_3], 4)\n",
        "    end_points[end_point] = net\n",
        "    if self._final_endpoint == end_point: return net, end_points\n",
        "\n",
        "    end_point = 'Mixed_4d'\n",
        "    with tf.variable_scope(end_point):\n",
        "      with tf.variable_scope('Branch_0'):\n",
        "        branch_0 = Unit3D(output_channels=128, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "      with tf.variable_scope('Branch_1'):\n",
        "        branch_1 = Unit3D(output_channels=128, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "        branch_1 = Unit3D(output_channels=256, kernel_shape=[3, 3, 3],\n",
        "                          name='Conv3d_0b_3x3')(branch_1,\n",
        "                                                is_training=is_training)\n",
        "      with tf.variable_scope('Branch_2'):\n",
        "        branch_2 = Unit3D(output_channels=24, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "        branch_2 = Unit3D(output_channels=64, kernel_shape=[3, 3, 3],\n",
        "                          name='Conv3d_0b_3x3')(branch_2,\n",
        "                                                is_training=is_training)\n",
        "      with tf.variable_scope('Branch_3'):\n",
        "        branch_3 = tf.nn.max_pool3d(net, ksize=[1, 3, 3, 3, 1],\n",
        "                                    strides=[1, 1, 1, 1, 1], padding=snt.SAME,\n",
        "                                    name='MaxPool3d_0a_3x3')\n",
        "        branch_3 = Unit3D(output_channels=64, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0b_1x1')(branch_3,\n",
        "                                                is_training=is_training)\n",
        "      net = tf.concat([branch_0, branch_1, branch_2, branch_3], 4)\n",
        "    end_points[end_point] = net\n",
        "    if self._final_endpoint == end_point: return net, end_points\n",
        "\n",
        "    end_point = 'Mixed_4e'\n",
        "    with tf.variable_scope(end_point):\n",
        "      with tf.variable_scope('Branch_0'):\n",
        "        branch_0 = Unit3D(output_channels=112, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "      with tf.variable_scope('Branch_1'):\n",
        "        branch_1 = Unit3D(output_channels=144, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "        branch_1 = Unit3D(output_channels=288, kernel_shape=[3, 3, 3],\n",
        "                          name='Conv3d_0b_3x3')(branch_1,\n",
        "                                                is_training=is_training)\n",
        "      with tf.variable_scope('Branch_2'):\n",
        "        branch_2 = Unit3D(output_channels=32, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "        branch_2 = Unit3D(output_channels=64, kernel_shape=[3, 3, 3],\n",
        "                          name='Conv3d_0b_3x3')(branch_2,\n",
        "                                                is_training=is_training)\n",
        "      with tf.variable_scope('Branch_3'):\n",
        "        branch_3 = tf.nn.max_pool3d(net, ksize=[1, 3, 3, 3, 1],\n",
        "                                    strides=[1, 1, 1, 1, 1], padding=snt.SAME,\n",
        "                                    name='MaxPool3d_0a_3x3')\n",
        "        branch_3 = Unit3D(output_channels=64, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0b_1x1')(branch_3,\n",
        "                                                is_training=is_training)\n",
        "      net = tf.concat([branch_0, branch_1, branch_2, branch_3], 4)\n",
        "    end_points[end_point] = net\n",
        "    if self._final_endpoint == end_point: return net, end_points\n",
        "\n",
        "    end_point = 'Mixed_4f'\n",
        "    with tf.variable_scope(end_point):\n",
        "      with tf.variable_scope('Branch_0'):\n",
        "        branch_0 = Unit3D(output_channels=256, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "      with tf.variable_scope('Branch_1'):\n",
        "        branch_1 = Unit3D(output_channels=160, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "        branch_1 = Unit3D(output_channels=320, kernel_shape=[3, 3, 3],\n",
        "                          name='Conv3d_0b_3x3')(branch_1,\n",
        "                                                is_training=is_training)\n",
        "      with tf.variable_scope('Branch_2'):\n",
        "        branch_2 = Unit3D(output_channels=32, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "        branch_2 = Unit3D(output_channels=128, kernel_shape=[3, 3, 3],\n",
        "                          name='Conv3d_0b_3x3')(branch_2,\n",
        "                                                is_training=is_training)\n",
        "      with tf.variable_scope('Branch_3'):\n",
        "        branch_3 = tf.nn.max_pool3d(net, ksize=[1, 3, 3, 3, 1],\n",
        "                                    strides=[1, 1, 1, 1, 1], padding=snt.SAME,\n",
        "                                    name='MaxPool3d_0a_3x3')\n",
        "        branch_3 = Unit3D(output_channels=128, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0b_1x1')(branch_3,\n",
        "                                                is_training=is_training)\n",
        "      net = tf.concat([branch_0, branch_1, branch_2, branch_3], 4)\n",
        "    end_points[end_point] = net\n",
        "    if self._final_endpoint == end_point: return net, end_points\n",
        "\n",
        "    end_point = 'MaxPool3d_5a_2x2'\n",
        "    net = tf.nn.max_pool3d(net, ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1],\n",
        "                           padding=snt.SAME, name=end_point)\n",
        "    end_points[end_point] = net\n",
        "    if self._final_endpoint == end_point: return net, end_points\n",
        "\n",
        "    end_point = 'Mixed_5b'\n",
        "    with tf.variable_scope(end_point):\n",
        "      with tf.variable_scope('Branch_0'):\n",
        "        branch_0 = Unit3D(output_channels=256, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "      with tf.variable_scope('Branch_1'):\n",
        "        branch_1 = Unit3D(output_channels=160, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "        branch_1 = Unit3D(output_channels=320, kernel_shape=[3, 3, 3],\n",
        "                          name='Conv3d_0b_3x3')(branch_1,\n",
        "                                                is_training=is_training)\n",
        "      with tf.variable_scope('Branch_2'):\n",
        "        branch_2 = Unit3D(output_channels=32, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "        branch_2 = Unit3D(output_channels=128, kernel_shape=[3, 3, 3],\n",
        "                          name='Conv3d_0a_3x3')(branch_2,\n",
        "                                                is_training=is_training)\n",
        "      with tf.variable_scope('Branch_3'):\n",
        "        branch_3 = tf.nn.max_pool3d(net, ksize=[1, 3, 3, 3, 1],\n",
        "                                    strides=[1, 1, 1, 1, 1], padding=snt.SAME,\n",
        "                                    name='MaxPool3d_0a_3x3')\n",
        "        branch_3 = Unit3D(output_channels=128, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0b_1x1')(branch_3,\n",
        "                                                is_training=is_training)\n",
        "      net = tf.concat([branch_0, branch_1, branch_2, branch_3], 4)\n",
        "    end_points[end_point] = net\n",
        "    if self._final_endpoint == end_point: return net, end_points\n",
        "\n",
        "    end_point = 'Mixed_5c'\n",
        "    with tf.variable_scope(end_point):\n",
        "      with tf.variable_scope('Branch_0'):\n",
        "        branch_0 = Unit3D(output_channels=384, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "      with tf.variable_scope('Branch_1'):\n",
        "        branch_1 = Unit3D(output_channels=192, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "        branch_1 = Unit3D(output_channels=384, kernel_shape=[3, 3, 3],\n",
        "                          name='Conv3d_0b_3x3')(branch_1,\n",
        "                                                is_training=is_training)\n",
        "      with tf.variable_scope('Branch_2'):\n",
        "        branch_2 = Unit3D(output_channels=48, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n",
        "        branch_2 = Unit3D(output_channels=128, kernel_shape=[3, 3, 3],\n",
        "                          name='Conv3d_0b_3x3')(branch_2,\n",
        "                                                is_training=is_training)\n",
        "      with tf.variable_scope('Branch_3'):\n",
        "        branch_3 = tf.nn.max_pool3d(net, ksize=[1, 3, 3, 3, 1],\n",
        "                                    strides=[1, 1, 1, 1, 1], padding=snt.SAME,\n",
        "                                    name='MaxPool3d_0a_3x3')\n",
        "        branch_3 = Unit3D(output_channels=128, kernel_shape=[1, 1, 1],\n",
        "                          name='Conv3d_0b_1x1')(branch_3,\n",
        "                                                is_training=is_training)\n",
        "      net = tf.concat([branch_0, branch_1, branch_2, branch_3], 4)\n",
        "    end_points[end_point] = net\n",
        "    if self._final_endpoint == end_point: return net, end_points\n",
        "\n",
        "    end_point = 'Logits'\n",
        "    with tf.variable_scope(end_point):\n",
        "      net = tf.nn.avg_pool3d(net, ksize=[1, 2, 7, 7, 1],\n",
        "                             strides=[1, 1, 1, 1, 1], padding=snt.VALID)\n",
        "      net = tf.nn.dropout(net, dropout_keep_prob)\n",
        "      feature = Unit3D(output_channels=1024,\n",
        "                       kernel_shape=[1, 1, 1],\n",
        "                       activation_fn=None,\n",
        "                       use_batch_norm=False,\n",
        "                       use_bias=True,\n",
        "                       name='Conv3d_0c_1x1')(net)  # [B, T, 1, 1, 1024]\n",
        "      feature = tf.squeeze(feature, [2, 3])             # [B, T, 1024]\n",
        "      feature = tf.reduce_mean(feature, axis=1)         # [B, 1024]\n",
        "      end_points[end_point] = feature\n",
        "    return feature, end_points\n",
        "      # logits = Unit3D(output_channels=self._num_classes,\n",
        "      #                 kernel_shape=[1, 1, 1],\n",
        "      #                 activation_fn=None,\n",
        "      #                 use_batch_norm=False,\n",
        "      #                 use_bias=True,\n",
        "      #                 name='Conv3d_0c_1x1')(net, is_training=is_training)\n",
        "\n",
        "    #   if self._spatial_squeeze:\n",
        "    #     logits = tf.squeeze(logits, [2, 3], name='SpatialSqueeze')\n",
        "    # averaged_logits = tf.reduce_mean(logits, axis=1)\n",
        "    # end_points[end_point] = averaged_logits\n",
        "    # if self._final_endpoint == end_point: return averaged_logits, end_points\n",
        "\n",
        "    # end_point = 'Predictions'\n",
        "    # predictions = tf.nn.softmax(averaged_logits)\n",
        "    # end_points[end_point] = predictions\n",
        "    # return predictions, end_points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "eR5wbqNW9_TH"
      },
      "outputs": [],
      "source": [
        "class LandmarkSequentialModel(Model):\n",
        "    def __init__(self, feature_dim=225, max_frame=64):\n",
        "        super(LandmarkSequentialModel, self).__init__()\n",
        "\n",
        "        self.lstm1 = layers.LSTM(64, return_sequences=True, activation='relu',\n",
        "                                 input_shape=(max_frame, feature_dim))\n",
        "        self.lstm2 = layers.LSTM(128, return_sequences=True, activation='relu')\n",
        "        self.lstm3 = layers.LSTM(64, return_sequences=False, activation='relu')\n",
        "        self.dense1 = layers.Dense(64, activation='relu')\n",
        "        self.dense2 = layers.Dense(32, activation='relu')\n",
        "\n",
        "        self._built = False\n",
        "        self.max_frame = max_frame\n",
        "        self.feature_dim = feature_dim\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if not self._built:\n",
        "            dummy = tf.zeros((1, self.max_frame, self.feature_dim))\n",
        "            self.call(dummy)\n",
        "            self._built = True\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        x = self.lstm1(x)\n",
        "        x = self.lstm2(x)\n",
        "        x = self.lstm3(x)\n",
        "        x = self.dense1(x)\n",
        "        x = self.dense2(x)\n",
        "        return x  # [B, 32]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "AgCvUBu1-RZU"
      },
      "outputs": [],
      "source": [
        "class RGBLandmarkFusion(tf.keras.Model):\n",
        "    def __init__(self, i3d_model, num_classes=15, feature_dim=1662, max_frame=64):\n",
        "        super(RGBLandmarkFusion, self).__init__()\n",
        "        self.i3d_model = i3d_model\n",
        "        self.landmark_model = LandmarkSequentialModel(feature_dim=feature_dim, max_frame=max_frame)\n",
        "        self.dropout1 = tf.keras.layers.Dropout(0.5)\n",
        "        self.dense = tf.keras.layers.Dense(256, activation='relu')\n",
        "        self.dropout2 = tf.keras.layers.Dropout(0.3)\n",
        "        self.classifier = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        rgb_input, landmark_input = inputs\n",
        "\n",
        "        rgb_feat, _ = self.i3d_model(rgb_input, is_training=training)       # [B, 1024]\n",
        "        landmark_feat = self.landmark_model(landmark_input, training=training)  # [B, 32]\n",
        "\n",
        "        fusion = tf.concat([rgb_feat, landmark_feat], axis=-1)              # [B, 1056]\n",
        "        x = self.dropout1(fusion, training=training)\n",
        "        x = self.dense(x)\n",
        "        x = self.dropout2(x, training=training)\n",
        "        return self.classifier(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1I2v_Sqp-ZKb"
      },
      "outputs": [],
      "source": [
        "i3d_model = InceptionI3d()\n",
        "landmark_model = LandmarkSequentialModel(num_classes=15, max_frame=64)\n",
        "\n",
        "fusion_model = RGBLandmarkFusion(i3d_model=i3d_model,\n",
        "                                 landmark_model=landmark_model,\n",
        "                                 num_classes=15)\n",
        "\n",
        "fusion_model.compile(optimizer='adam',\n",
        "                     loss='sparse_categorical_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "fusion_model.fit(\n",
        "    x=[rgb_input, landmark_input],\n",
        "    y=labels,\n",
        "    batch_size=8,\n",
        "    epochs=20\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
